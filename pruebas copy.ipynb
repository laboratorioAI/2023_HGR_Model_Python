{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Function model\n",
    "def set_neural_network_architecture(input_size, num_classes):\n",
    "\n",
    "    # Entradas\n",
    "    sequence=tf.keras.layers.Input(shape=input_size)\n",
    "    \n",
    "    # Add layer branches\n",
    "    # Primer bloque\n",
    "    Inception_1a_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(sequence)\n",
    "    Inception_1a_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1a_3x3_reduce)\n",
    "    Inception_1a_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1a_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1a_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(sequence)\n",
    "    \n",
    "    Inception_1a_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(sequence)\n",
    "    Inception_1a_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1a_pool)\n",
    "\n",
    "    \n",
    "    Inception_1a_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(sequence)\n",
    "    Inception_1a_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1a_5x5_reduce)\n",
    "    Inception_1a_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1a_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1a = tf.keras.layers.Concatenate(axis=-1)([Inception_1a_3x3, Inception_1a_1x1, Inception_1a_pool_proj, Inception_1a_5x5])\n",
    "    Inception_1a_relu = tf.keras.layers.ReLU()(depthcat_1a)\n",
    "\n",
    "    # Segundo bloque\n",
    "    Inception_1b_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1a_relu)\n",
    "    Inception_1b_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1b_3x3_reduce)\n",
    "    Inception_1b_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1b_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1b_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1a_relu)\n",
    "    \n",
    "    Inception_1b_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1a_relu)\n",
    "    Inception_1b_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1b_pool)\n",
    "\n",
    "    \n",
    "    Inception_1b_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1a_relu)\n",
    "    Inception_1b_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1b_5x5_reduce)\n",
    "    Inception_1b_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1b_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1b = tf.keras.layers.Concatenate(axis=-1)([Inception_1b_3x3,Inception_1b_1x1,Inception_1b_pool_proj,Inception_1b_5x5])\n",
    "    Inception_1b_relu = tf.keras.layers.ReLU()(depthcat_1b)\n",
    "    \n",
    "\n",
    "    # Tercer bloque\n",
    "    Inception_1c_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1b_relu)\n",
    "    Inception_1c_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1c_3x3_reduce)\n",
    "    Inception_1c_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1c_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1c_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1b_relu)\n",
    "    \n",
    "    Inception_1c_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1b_relu)\n",
    "    Inception_1c_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1c_pool)\n",
    "\n",
    "    \n",
    "    Inception_1c_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1b_relu)\n",
    "    Inception_1c_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1c_5x5_reduce)\n",
    "    Inception_1c_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1c_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1c = tf.keras.layers.Concatenate(axis=-1)([Inception_1c_3x3,Inception_1c_1x1,Inception_1c_pool_proj,Inception_1c_5x5])\n",
    "    \n",
    "    #       Adición Layer\n",
    "\n",
    "    Addition_1 = tf.keras.layers.Add()([depthcat_1c, Inception_1a_relu])\n",
    "    Addition_1_relu = tf.keras.layers.ReLU()(Addition_1)\n",
    "\n",
    "    # Cuarto bloque\n",
    "    \n",
    "    Inception_1d_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_1_relu)\n",
    "    Inception_1d_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1d_3x3_reduce)\n",
    "    Inception_1d_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1d_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1d_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Addition_1_relu)\n",
    "    \n",
    "    Inception_1d_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Addition_1_relu)\n",
    "    Inception_1d_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1d_pool)\n",
    "\n",
    "    \n",
    "    Inception_1d_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_1_relu)\n",
    "    Inception_1d_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1d_5x5_reduce)\n",
    "    Inception_1d_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1d_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1d = tf.keras.layers.Concatenate(axis=-1)([Inception_1d_3x3,Inception_1d_1x1,Inception_1d_pool_proj,Inception_1d_5x5])\n",
    "    Inception_1d_relu = tf.keras.layers.ReLU()(depthcat_1d)\n",
    "\n",
    "    # Quinto bloque\n",
    "    \n",
    "    Inception_1e_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1d_relu)\n",
    "    Inception_1e_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1e_3x3_reduce)\n",
    "    Inception_1e_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1e_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1e_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1d_relu)\n",
    "    \n",
    "    Inception_1e_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1d_relu)\n",
    "    Inception_1e_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1e_pool)\n",
    "\n",
    "    \n",
    "    Inception_1e_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1d_relu)\n",
    "    Inception_1e_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1e_5x5_reduce)\n",
    "    Inception_1e_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1e_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1e = tf.keras.layers.Concatenate(axis=-1)([Inception_1e_3x3,Inception_1e_1x1,Inception_1e_pool_proj,Inception_1e_5x5])\n",
    "    \n",
    "    #       Adición Layer\n",
    "\n",
    "    Addition_2 = tf.keras.layers.Add()([depthcat_1e, Addition_1_relu])\n",
    "    Addition_2_relu = tf.keras.layers.ReLU()(Addition_2)\n",
    "\n",
    "    # Sexto bloque\n",
    "    \n",
    "    Inception_1f_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_2_relu)\n",
    "    Inception_1f_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1f_3x3_reduce)\n",
    "    Inception_1f_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1f_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1f_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Addition_2_relu)\n",
    "    \n",
    "    Inception_1f_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Addition_2_relu)\n",
    "    Inception_1f_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1f_pool)\n",
    "\n",
    "    \n",
    "    Inception_1f_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_2_relu)\n",
    "    Inception_1f_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1f_5x5_reduce)\n",
    "    Inception_1f_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1f_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1f = tf.keras.layers.Concatenate(axis=-1)([Inception_1f_3x3,Inception_1f_1x1,Inception_1f_pool_proj,Inception_1f_5x5])\n",
    "\n",
    "    # Normalizacion\n",
    "    Batch_normalization = tf.keras.layers.BatchNormalization()(depthcat_1f)\n",
    "\n",
    "    # Aplanado\n",
    "    Flatten = tf.keras.layers.Flatten()(Batch_normalization)\n",
    "    # LSTM\n",
    "    Lstm =  tf.keras.layers.LSTM(128, return_sequences=True)(Flatten)\n",
    "\n",
    "    dense_classification = tf.keras.layers.Dense(num_classes, activation='softmax', name='classoutput')(Lstm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=sequence, outputs=dense_classification)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "\n",
    "# Directorio que contiene los archivos JSON\n",
    "directorio = 'StaticData'\n",
    "\n",
    "# Patrón para buscar archivos JSON\n",
    "patron_archivos = os.path.join(directorio, '*.json')\n",
    "\n",
    "# Obtener la lista de archivos JSON en el directorio\n",
    "archivos_json = glob.glob(patron_archivos)\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre los archivos JSON\n",
    "for archivo_json in archivos_json:\n",
    "    # Cargar el archivo JSON como DataFrame\n",
    "    df = pd.read_json(archivo_json)\n",
    "    # Agregar el DataFrame a la lista\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combinar los DataFrames en uno solo\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Filtrar los valores nulos en la columna \"Spectograms\"\n",
    "df_completo_filtrado = df_completo.dropna(subset=['Spectograms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Spectograms    Gesture  \\\n",
      "0        [[[0.0, 1e-10, 6.06e-08, 3.6e-09, 1e-10, 1.37e...  noGesture   \n",
      "1        [[[0.0, 3e-10, 2.0950000000000002e-07, 4.5e-09...  noGesture   \n",
      "2        [[[0.0, 1.2e-09, 2.079e-07, 3.3e-09, 3.3e-09, ...  noGesture   \n",
      "3        [[[2e-10, 1.9e-09, 8.05e-08, 4e-10, 2e-09, 1.7...     waveIn   \n",
      "4        [[[2e-10, 1e-09, 6.3e-09, 5e-10, 0.0, 7.6e-09,...     waveIn   \n",
      "...                                                    ...        ...   \n",
      "6221706  [[[3.717e-07, 1.8100000000000002e-07, 2.99e-08...     waveIn   \n",
      "6221707  [[[1.842e-07, 1.479e-07, 7.45e-08, 1.554e-07, ...     waveIn   \n",
      "6221708  [[[5.21e-08, 5.21e-08, 1.0230000000000001e-07,...  noGesture   \n",
      "6221709  [[[2.1e-09, 3.4000000000000003e-09, 1.312e-07,...  noGesture   \n",
      "6221710  [[[5.7000000000000006e-09, 3.3e-09, 1.133e-07,...  noGesture   \n",
      "\n",
      "         Timestamp                                  Quat_Spectrograms  0  \n",
      "0            240.0  [[[0.0, 8.023140852e-37, 0.0, 0.0], [4.1998258...  0  \n",
      "1            255.0  [[[7.224118205e-36, 2.006177025e-37, 2.0543252...  0  \n",
      "2            270.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], ...  0  \n",
      "3            285.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], ...  0  \n",
      "4            300.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], ...  0  \n",
      "...            ...                                                ... ..  \n",
      "6221706      630.0  [[[0.0, 0.0, 0.0, 3.922673628e-36], [0.0, 0.0,...  0  \n",
      "6221707      645.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 3e-10, 2e-1...  0  \n",
      "6221708      660.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], ...  0  \n",
      "6221709      675.0  [[[2.7813611829999997e-36, 0.0, 0.0, 0.0], [0....  0  \n",
      "6221710      690.0  [[[0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0], ...  0  \n",
      "\n",
      "[106579 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Muestra de los datos\n",
    "print(df_completo_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Obtén las características y las etiquetas de entrenamiento y validación\n",
    "x_train = train_df['Spectograms'].values\n",
    "y_train = train_df['Gesture'].values\n",
    "x_val = val_df['Spectograms'].values\n",
    "y_val = val_df['Gesture'].values\n",
    "\n",
    "# Convierte las características y las etiquetas en matrices NumPy\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 22464)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\USER\\Documents\\Tesis\\CodigoTesis\\pruebas.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Configuración del entorno GPU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(gpu_device):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Definir la arquitectura de la red neuronal\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model \u001b[39m=\u001b[39m set_neural_network_architecture(input_size, num_classes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Compilar el modelo\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39minitial_learn_rate),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                   loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\USER\\Documents\\Tesis\\CodigoTesis\\pruebas.ipynb Cell 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m Flatten \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten()(Batch_normalization)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m \u001b[39m# LSTM\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m Lstm \u001b[39m=\u001b[39m  tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLSTM(\u001b[39m128\u001b[39;49m, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)(Flatten)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m dense_classification \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassoutput\u001b[39m\u001b[39m'\u001b[39m)(Lstm)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/USER/Documents/Tesis/CodigoTesis/pruebas.ipynb#W4sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39msequence, outputs\u001b[39m=\u001b[39mdense_classification)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\curso_deep_learning\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[0;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[0;32m    553\u001b[0m )\n\u001b[0;32m    555\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    562\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\curso_deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\curso_deep_learning\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 22464)"
     ]
    }
   ],
   "source": [
    "# Configuración de las opciones de entrenamiento\n",
    "gpu_device = \"/gpu:1\"\n",
    "max_epochs = 60\n",
    "mini_batch_size = 64\n",
    "initial_learn_rate = 0.04\n",
    "learn_rate_drop_factor = 0.2\n",
    "learn_rate_drop_period = 8\n",
    "gradient_threshold = 1\n",
    "validation_patience = 5\n",
    "\n",
    "input_size = (13,24,8)\n",
    "num_classes = 6\n",
    "\n",
    "# Configuración del entorno GPU\n",
    "with tf.device(gpu_device):\n",
    "    # Definir la arquitectura de la red neuronal\n",
    "    model = set_neural_network_architecture(input_size, num_classes)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=initial_learn_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Configuración de las callbacks\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * learn_rate_drop_factor if epoch % learn_rate_drop_period == 0 else lr)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=validation_patience)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(x_train, y_train, epochs=max_epochs, batch_size=mini_batch_size, \n",
    "                    validation_data=(x_val, y_val), shuffle=False, verbose=1,\n",
    "                    callbacks=[lr_scheduler, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
