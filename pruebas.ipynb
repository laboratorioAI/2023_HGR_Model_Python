{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function model\n",
    "def set_neural_network_architecture(input_size, num_classes):\n",
    "\n",
    "    # Entradas\n",
    "    sequence=tf.keras.layers.Input(shape=input_size)\n",
    "    \n",
    "    # Add layer branches\n",
    "    # Primer bloque\n",
    "    Inception_1a_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(sequence)\n",
    "    Inception_1a_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1a_3x3_reduce)\n",
    "    Inception_1a_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1a_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1a_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(sequence)\n",
    "    \n",
    "    Inception_1a_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(sequence)\n",
    "    Inception_1a_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1a_pool)\n",
    "\n",
    "    \n",
    "    Inception_1a_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(sequence)\n",
    "    Inception_1a_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1a_5x5_reduce)\n",
    "    Inception_1a_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1a_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1a = tf.keras.layers.Concatenate(axis=-1)([Inception_1a_3x3, Inception_1a_1x1, Inception_1a_pool_proj, Inception_1a_5x5])\n",
    "    Inception_1a_relu = tf.keras.layers.ReLU()(depthcat_1a)\n",
    "\n",
    "    # Segundo bloque\n",
    "    Inception_1b_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1a_relu)\n",
    "    Inception_1b_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1b_3x3_reduce)\n",
    "    Inception_1b_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1b_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1b_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1a_relu)\n",
    "    \n",
    "    Inception_1b_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1a_relu)\n",
    "    Inception_1b_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1b_pool)\n",
    "\n",
    "    \n",
    "    Inception_1b_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1a_relu)\n",
    "    Inception_1b_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1b_5x5_reduce)\n",
    "    Inception_1b_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1b_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1b = tf.keras.layers.Concatenate(axis=-1)([Inception_1b_3x3,Inception_1b_1x1,Inception_1b_pool_proj,Inception_1b_5x5])\n",
    "    Inception_1b_relu = tf.keras.layers.ReLU()(depthcat_1b)\n",
    "    \n",
    "\n",
    "    # Tercer bloque\n",
    "    Inception_1c_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1b_relu)\n",
    "    Inception_1c_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1c_3x3_reduce)\n",
    "    Inception_1c_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1c_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1c_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1b_relu)\n",
    "    \n",
    "    Inception_1c_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1b_relu)\n",
    "    Inception_1c_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1c_pool)\n",
    "\n",
    "    \n",
    "    Inception_1c_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1b_relu)\n",
    "    Inception_1c_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1c_5x5_reduce)\n",
    "    Inception_1c_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1c_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1c = tf.keras.layers.Concatenate(axis=-1)([Inception_1c_3x3,Inception_1c_1x1,Inception_1c_pool_proj,Inception_1c_5x5])\n",
    "    \n",
    "    #       Adición Layer\n",
    "\n",
    "    Addition_1 = tf.keras.layers.Add()([depthcat_1c, Inception_1a_relu])\n",
    "    Addition_1_relu = tf.keras.layers.ReLU()(Addition_1)\n",
    "\n",
    "    # Cuarto bloque\n",
    "    \n",
    "    Inception_1d_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_1_relu)\n",
    "    Inception_1d_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1d_3x3_reduce)\n",
    "    Inception_1d_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1d_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1d_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Addition_1_relu)\n",
    "    \n",
    "    Inception_1d_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Addition_1_relu)\n",
    "    Inception_1d_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1d_pool)\n",
    "\n",
    "    \n",
    "    Inception_1d_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_1_relu)\n",
    "    Inception_1d_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1d_5x5_reduce)\n",
    "    Inception_1d_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1d_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1d = tf.keras.layers.Concatenate(axis=-1)([Inception_1d_3x3,Inception_1d_1x1,Inception_1d_pool_proj,Inception_1d_5x5])\n",
    "    Inception_1d_relu = tf.keras.layers.ReLU()(depthcat_1d)\n",
    "\n",
    "    # Quinto bloque\n",
    "    \n",
    "    Inception_1e_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1d_relu)\n",
    "    Inception_1e_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1e_3x3_reduce)\n",
    "    Inception_1e_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1e_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1e_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1d_relu)\n",
    "    \n",
    "    Inception_1e_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Inception_1d_relu)\n",
    "    Inception_1e_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1e_pool)\n",
    "\n",
    "    \n",
    "    Inception_1e_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Inception_1d_relu)\n",
    "    Inception_1e_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1e_5x5_reduce)\n",
    "    Inception_1e_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1e_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1e = tf.keras.layers.Concatenate(axis=-1)([Inception_1e_3x3,Inception_1e_1x1,Inception_1e_pool_proj,Inception_1e_5x5])\n",
    "    \n",
    "    #       Adición Layer\n",
    "\n",
    "    Addition_2 = tf.keras.layers.Add()([depthcat_1e, Addition_1_relu])\n",
    "    Addition_2_relu = tf.keras.layers.ReLU()(Addition_2)\n",
    "\n",
    "    # Sexto bloque\n",
    "    \n",
    "    Inception_1f_3x3_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_2_relu)\n",
    "    Inception_1f_3x3_relu_reduce = tf.keras.layers.ReLU()(Inception_1f_3x3_reduce)\n",
    "    Inception_1f_3x3 = tf.keras.layers.Conv2D(18, (3, 3), padding='same')(Inception_1f_3x3_relu_reduce)\n",
    "    \n",
    "    Inception_1f_1x1 = tf.keras.layers.Conv2D(18, (1, 1))(Addition_2_relu)\n",
    "    \n",
    "    Inception_1f_pool = tf.keras.layers.MaxPooling2D((3, 3), padding='same', strides=(1,1))(Addition_2_relu)\n",
    "    Inception_1f_pool_proj = tf.keras.layers.Conv2D(18, (1, 1))(Inception_1f_pool)\n",
    "\n",
    "    \n",
    "    Inception_1f_5x5_reduce = tf.keras.layers.Conv2D(16, (1, 1))(Addition_2_relu)\n",
    "    Inception_1f_5x5_relu_reduce = tf.keras.layers.ReLU()(Inception_1f_5x5_reduce)\n",
    "    Inception_1f_5x5 = tf.keras.layers.Conv2D(18, (5, 5), padding='same')(Inception_1f_5x5_relu_reduce)\n",
    "\n",
    "    depthcat_1f = tf.keras.layers.Concatenate(axis=-1)([Inception_1f_3x3,Inception_1f_1x1,Inception_1f_pool_proj,Inception_1f_5x5])\n",
    "\n",
    "    # Normalizacion\n",
    "    Batch_normalization = tf.keras.layers.BatchNormalization()(depthcat_1f)\n",
    "\n",
    "    # Aplanado\n",
    "    \n",
    "    Flatten = tf.keras.layers.Flatten()(Batch_normalization)\n",
    "\n",
    "    # Reshape\n",
    "    Reshape = tf.keras.layers.Reshape((22464, 1))(Flatten)\n",
    "\n",
    "    # LSTM\n",
    "    Lstm = tf.keras.layers.LSTM(128, return_sequences=False)(Reshape)\n",
    "\n",
    "    dense_classification = tf.keras.layers.Dense(num_classes, activation='softmax', name='classoutput')(Lstm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=sequence, outputs=dense_classification)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos\n",
    "\n",
    "# Directorio que contiene los archivos JSON\n",
    "directorio = 'StaticData'\n",
    "\n",
    "# Patrón para buscar archivos JSON\n",
    "patron_archivos = os.path.join(directorio, '*.json')\n",
    "\n",
    "# Obtener la lista de archivos JSON en el directorio\n",
    "archivos_json = glob.glob(patron_archivos)\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre los archivos JSON\n",
    "for archivo_json in archivos_json:\n",
    "    # Cargar el archivo JSON como DataFrame\n",
    "    df = pd.read_json(archivo_json)\n",
    "    # Agregar el DataFrame a la lista\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Combinar los DataFrames en uno solo\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Filtrar los valores nulos en la columna \"Spectograms\"\n",
    "#df_completo_filtrado = df_completo.dropna(subset=['Spectograms'])\n",
    "\n",
    "#df_completo.to_json('static.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra de los datos\n",
    "print(df_completo)\n",
    "df_completo.to_json('static.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide los datos en entrenamiento y validación\n",
    "train_df, val_df = train_test_split(df_completo, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Obtén las características y las etiquetas de entrenamiento y validación\n",
    "x_train = train_df['Spectograms'].values\n",
    "y_train = train_df['Gesture'].values\n",
    "x_val = val_df['Spectograms'].values\n",
    "y_val = val_df['Gesture'].values\n",
    "\n",
    "# Convierte las características y las etiquetas en matrices NumPy\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_train_reshaped = []\n",
    "x_val_reshaped = []\n",
    "\n",
    "# Aplicar el remodelado a cada valor de la lista\n",
    "for valor in x_train:\n",
    "    arreglo_reshaped = np.array(valor).reshape((13, 24, 8))\n",
    "    x_train_reshaped.append(arreglo_reshaped)\n",
    "\n",
    "# Aplicar el remodelado a cada valor de la lista\n",
    "for valor in x_val:\n",
    "    arreglo_reshaped = np.array(valor).reshape((13, 24, 8))\n",
    "    x_val_reshaped.append(arreglo_reshaped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106660\n",
      "(13, 24, 8)\n",
      "(106660,)\n",
      "26665\n",
      "(13, 24, 8)\n",
      "(26665,)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_reshaped))\n",
    "print(x_train_reshaped[0].shape)\n",
    "print(y_train.shape)\n",
    "print(len(x_val_reshaped))\n",
    "print(x_val_reshaped[0].shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train_reshaped)\n",
    "x_val = np.array(x_val_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_val))\n",
    "print(type(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Configuración de las opciones de entrenamiento\n",
    "gpu_device = \"/gpu:1\"\n",
    "max_epochs = 60\n",
    "mini_batch_size = 64\n",
    "initial_learn_rate = 0.04\n",
    "learn_rate_drop_factor = 0.2\n",
    "learn_rate_drop_period = 8\n",
    "gradient_threshold = 1\n",
    "validation_patience = 5\n",
    "\n",
    "input_size = (13,24,8)\n",
    "num_classes = 6\n",
    "\n",
    "# Configuración del entorno GPU\n",
    "with tf.device(gpu_device):\n",
    "    # Definir la arquitectura de la red neuronal\n",
    "    model = set_neural_network_architecture(input_size, num_classes)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=initial_learn_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "# Convertir las etiquetas en valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "\n",
    "# Obtener el número de clases\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Convertir las etiquetas en one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_val_encoded = to_categorical(y_val_encoded, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Configuración de las callbacks\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * learn_rate_drop_factor if epoch % learn_rate_drop_period == 0 else lr)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=validation_patience)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "history = model.fit(x_train, y_train_encoded, epochs=max_epochs, batch_size=mini_batch_size, \n",
    "                    validation_data=(x_val, y_val_encoded), shuffle=False, verbose=1,\n",
    "                    callbacks=[lr_scheduler, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curso_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
